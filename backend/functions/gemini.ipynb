{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install google-genai\n",
    "%pip install dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from typing import Callable, Optional, List, Dict, Any\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-agent systems involve multiple autonomous entities interacting to achieve individual and/or collective goals.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=os.environ.get(\"GEMINI_API_KEY\"))\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=\"Explain how multi-agent works in one sentences\"\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-turn conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, bet.\n",
      "\n",
      "Why did the coffee go to the police?\n",
      "\n",
      "... Because it got **mugged**, no cap! ‚òïüëÆ‚Äç‚ôÇÔ∏è\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat = client.chats.create(model=\"gemini-2.0-flash\")\n",
    "response = chat.send_message(\"Tell me a dad joke in gen-z language\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aight, chill, chill. Let me hit you with this one:\n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "... Because they make up everything, fr fr! üß™üß¢\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Tell me a dad joke in gen-z language\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"model\",\n",
    "        \"content\": \"Okay, bet.\\n\\nWhy did the coffee go to the police?\\n\\n... Because it got **mugged**, no cap! ‚òïüëÆ‚Äç‚ôÇÔ∏è\"\n",
    "    },\n",
    "]\n",
    "\n",
    "formatted_history = []\n",
    "for message in history:\n",
    "    formatted_history.append(\n",
    "        genai.types.Content(\n",
    "            role=message[\"role\"],\n",
    "            parts=[genai.types.Part.from_text(text=message[\"content\"])]\n",
    "        )\n",
    "    )\n",
    "\n",
    "chat = client.chats.create(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    history=formatted_history,\n",
    "    config={\"system_instruction\": \"You are a helpful assistant that tells dad jokes in gen-z language.\"}\n",
    ")\n",
    "response = chat.send_message(\"That's lame! tell me another one\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay\n",
      ", imagine you're building a LEGO city!\n",
      "\n",
      "You're one builder\n",
      ", right? But it's a *big* city! It would take you\n",
      " a really long time to do it all by yourself.\n",
      "\n",
      "Multi-agent is like having lots of LEGO builders, all working together to build the city faster and better.\n",
      "\n",
      "\n",
      "*   **Each builder is an \"agent.\"** Just like you, they can build LEGO pieces.\n",
      "*   **Each agent has a job.** One\n",
      " might be in charge of building houses, another builds the police station, and another builds the park.\n",
      "*   **They talk to each other!** Maybe the house builder needs more red bricks, so he asks the brick supplier agent.  Or maybe\n",
      " the park builder needs to know where the roads are going so he can plan the park layout!\n",
      "*   **They all work towards a big goal.** The big goal is to build a whole awesome LEGO city!\n",
      "\n",
      "So, instead of one person,\n",
      " you have many little \"helpers\" (agents) working together to solve a problem, like building a LEGO city, but it could be used to solve other problems too, like making self driving cars, or even robots that clean your room!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chat = client.chats.create(model=\"gemini-2.0-flash\")\n",
    "response_iterator = chat.send_message_stream(\"Teach me how multi-agent works as if I'm 5.\")\n",
    "for chunk in response_iterator:\n",
    "    if chunk.text:\n",
    "        print(chunk.text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
